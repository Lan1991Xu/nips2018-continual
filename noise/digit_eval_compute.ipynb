{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from salad.datasets import DigitsLoader\n",
    "import torch\n",
    "from salad.utils import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions for digit dataset multi-class training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_data(source):\n",
    "\n",
    "    datasets = ['mnist', 'usps', 'synth', 'svhn']\n",
    "    datasets.pop(datasets.index(source))\n",
    "    datasets = [source] + datasets\n",
    "\n",
    "    loader   = DigitsLoader('/tmp/data', datasets, download=True, shuffle=False, batch_size=64, drop_last=False,\n",
    "                                                   normalize=True, num_workers=4, split=\"test\")\n",
    "    \n",
    "    return loader, datasets\n",
    "\n",
    "def run_eval(source, datasets, loader):\n",
    "\n",
    "    fname = list(glob.glob(\"log/digits/{}/*_MultidomainBCESolver/*-checkpoint-ep99.pth\".format(source)))\n",
    "    #assert len(fname) == 1, fname\n",
    "    fname = fname[0]\n",
    "    \n",
    "    print(fname)\n",
    "\n",
    "    acc = {}\n",
    "\n",
    "    for adapt in datasets:\n",
    "        for i, target in enumerate(datasets):\n",
    "            lbl, pred, _ = evaluate.evaluate([fname], loader.datasets[i], domain = datasets.index(adapt))\n",
    "            acc[(source, adapt, target)] = [lbl, pred]\n",
    "            \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize data\n",
      "Normalize data\n",
      "Extracting /tmp/data/zip.train.gz\n",
      "Normalize data\n",
      "Extracting /tmp/data/synth_test_32x32.mat?raw=true\n",
      "Normalize data\n",
      "Using downloaded and verified file: /tmp/data/test_32x32.mat\n",
      "log/digits/mnist/20180926-125754_MultidomainBCESolver/20180926-125754-checkpoint-ep99.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 80.56it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 79.79it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 80.77it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 86.63it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 80.93it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 77.46it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 82.94it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 85.65it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 81.77it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 77.13it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 83.58it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 86.72it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 82.35it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 74.43it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 80.81it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 88.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize data\n",
      "Extracting /tmp/data/zip.train.gz\n",
      "Normalize data\n",
      "Normalize data\n",
      "Extracting /tmp/data/synth_test_32x32.mat?raw=true\n",
      "Normalize data\n",
      "Using downloaded and verified file: /tmp/data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/114 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/digits/usps/20180926-130054_MultidomainBCESolver/20180926-130054-checkpoint-ep99.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:01<00:00, 78.16it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 80.25it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 80.70it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 87.59it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 77.05it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 79.64it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 80.45it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 83.66it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 76.40it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 78.56it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 80.03it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 87.71it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 77.02it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 80.68it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 78.72it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 86.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize data\n",
      "Extracting /tmp/data/synth_test_32x32.mat?raw=true\n",
      "Normalize data\n",
      "Normalize data\n",
      "Extracting /tmp/data/zip.train.gz\n",
      "Normalize data\n",
      "Using downloaded and verified file: /tmp/data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/digits/synth/20180926-125253_MultidomainBCESolver/20180926-125253-checkpoint-ep99.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:01<00:00, 79.68it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 80.73it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 73.10it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 84.99it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 78.27it/s]\n",
      "100%|██████████| 157/157 [00:02<00:00, 78.19it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 76.57it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 87.66it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 80.15it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 83.31it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 79.18it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 87.90it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 80.37it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 82.31it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 76.51it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 85.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize data\n",
      "Using downloaded and verified file: /tmp/data/test_32x32.mat\n",
      "Normalize data\n",
      "Normalize data\n",
      "Extracting /tmp/data/zip.train.gz\n",
      "Normalize data\n",
      "Extracting /tmp/data/synth_test_32x32.mat?raw=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/407 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/digits/svhn/20180926-143322_MultidomainBCESolver/20180926-143322-checkpoint-ep99.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [00:04<00:00, 86.40it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 79.84it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 75.72it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 78.86it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 86.40it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 79.82it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 78.45it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 78.74it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 86.54it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 79.58it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 77.47it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 78.96it/s]\n",
      "100%|██████████| 407/407 [00:04<00:00, 86.38it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 80.83it/s]\n",
      "100%|██████████| 114/114 [00:01<00:00, 76.85it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 79.83it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "sources = ['mnist', 'usps', 'synth', 'svhn']\n",
    "\n",
    "for source in sources:\n",
    "    loader, datasets = get_data(source)\n",
    "    predictions.update(run_eval(source, datasets, loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(\"results/digit_predictions.hdf5\") as ds:\n",
    "    \n",
    "    for key in predictions:\n",
    "        \n",
    "        ds_key = \"-\".join(key)\n",
    "        \n",
    "        grp = ds.require_group(ds_key)\n",
    "        \n",
    "        lbls, pred = predictions[key]\n",
    "        \n",
    "        grp[\"prediction\"] = pred\n",
    "        grp[\"labels\"] = lbls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39M\tresults/digit_predictions.hdf5\n"
     ]
    }
   ],
   "source": [
    "! du -h results/digit_predictions.hdf5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
