{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import analysis\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import analysis\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Results\n",
    "\n",
    "The analysis we report in our paper can be reproduced on several levels:\n",
    "\n",
    "   - Training a new model. This produces a new log in `log/` with model checkpoints (`.pth`) and loss histories (`losshistory.csv`)\n",
    "   - Generating model predictions on a test set, using a model checkpoint. This generates a `hdf` dataset in `results/`, containing label informations and model predictions.\n",
    "   - Generating result tables and plots. This is done interactively in this file.\n",
    "\n",
    "\n",
    "## Digit Datasets\n",
    "\n",
    "Prediction and label loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results():\n",
    "    with h5py.File(\"results/digits/digit_predictions.hdf5\") as ds:\n",
    "\n",
    "        for key in ds.keys():\n",
    "\n",
    "            source, adapt, test = key.split(\"-\")\n",
    "\n",
    "            preds = ds[key][\"prediction\"][...].squeeze()\n",
    "            lbls = ds[key][\"labels\"][...].squeeze()\n",
    "\n",
    "            acc = (preds.argmax(axis=-1) == lbls).mean()\n",
    "\n",
    "            yield [source, adapt, test, acc]\n",
    "            \n",
    "df = pd.DataFrame(load_results(), columns = [\"source\", \"adapt\", \"test\", \"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['mnist', 'usps', 'synth', 'svhn']\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "source_lbl = \"Train\"\n",
    "adapt_test_lbl = \"Adapt + Test\"\n",
    "test_lbl = \"Test\"\n",
    "adapt_lbl = \"Adapt\"\n",
    "\n",
    "action = plt.close\n",
    "\n",
    "with PdfPages(\"results/digit-plots.pdf\") as pdf:\n",
    "    \n",
    "    order = ['mnist', 'usps', 'synth', 'svhn']\n",
    "    adapt = df[df.adapt == df.test].pivot(\"source\", \"adapt\", \"acc\")[order].reindex(order)\n",
    "\n",
    "    sns.set_context('poster')\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(data=100*adapt, cmap = 'Blues', annot = True, fmt='.1f', square=True, linewidths=1, cbar=None, vmin=65, vmax=100)\n",
    "    \n",
    "    plt.xlabel(adapt_test_lbl)\n",
    "    plt.ylabel(source_lbl)\n",
    "    \n",
    "    pdf.savefig(bbox_inches=\"tight\")\n",
    "    \n",
    "    action()\n",
    "\n",
    "    for source in order:\n",
    "\n",
    "        adapt = df[df.source == source].pivot(\"adapt\", \"test\", \"acc\")[order].reindex(order)\n",
    "\n",
    "        sns.set_context('poster')\n",
    "        plt.figure(figsize=(7,7))\n",
    "        sns.heatmap(data=100*adapt, cmap = 'Blues', annot = True, fmt='.1f', square=True, linewidths=1, vmin=30, vmax=100)\n",
    "        plt.title(\"Train: \" +source)\n",
    "        \n",
    "        plt.xlabel(test_lbl)\n",
    "        plt.ylabel(adapt_lbl)\n",
    "        \n",
    "        pdf.savefig(bbox_inches=\"tight\")\n",
    "        action()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Learning for Noise Adaptation\n",
    "\n",
    "We evaluate models after 90 epochs of training and adaptation on the SVHN dataset, with varying degrees and types of noise, namely\n",
    "\n",
    "- Clean data vs. White Noise (\"white\")\n",
    "- Clean data vs. Salt and Pepper Noise (\"snp\")\n",
    "- White Noise vs. Salt and Pepper Noise (\"mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_analysis(ACC, imgs, noise_vars, P, title, sym):\n",
    "    \n",
    "    titles = ['${}={}$'.format(sym, i) for i in noise_vars]\n",
    "    \n",
    "    fig, ax = analysis.plot_overview(ACC, imgs, noise_vars, titles) \n",
    "    ax.set_title(title)\n",
    "    yield fig\n",
    "\n",
    "    names = ['Mean', 'Variance', u'$\\gamma$', u'$\\\\beta$', 'Scale', 'Shift']\n",
    "\n",
    "    sns.set_context('poster', font_scale=.9)\n",
    "    for m, name in zip(P, names):\n",
    "        m = m.squeeze()\n",
    "\n",
    "        fig, (ax_angle, ax_acc, ax_tril) = plt.subplots(1,3,figsize=(15,5))\n",
    "        a = analysis.compute_angle(m)\n",
    "        analysis.transfer_plot(a,ACC,ax_angle, ax_acc, noise_vars)\n",
    "\n",
    "        ax_angle.text(s=name, x=-3,y = -.75, color='gray')\n",
    "        ax_angle.text(s=u'$\\sigma_{train} > \\sigma_{test}$',x=-.2,y=6.5,color='white')\n",
    "        ax_angle.text(s=u'$\\sigma_{test} > \\sigma_{train}$',x=3,y=1.25,color='white')\n",
    "\n",
    "        #ax_tril, ax_triu = plt.subplots(1,2,figsize=(10,3))[1] #,sharex=True,sharey=True)[1]\n",
    "        x,y = analysis.get_corr(ACC.T, a, np.triu)\n",
    "        analysis.plot_reg(x, y, ax=ax_tril)\n",
    "        ax_tril.set_title('Correlation ($\\sigma_{test} > \\sigma_{train}$)')\n",
    "        #x,y = get_corr(ACC, a, np.triu)\n",
    "        #plot_reg(x, y, ax=ax_triu)\n",
    "        #plt.suptitle(name)\n",
    "        #plt.show()\n",
    "\n",
    "        xticks = ax_tril.get_xticks()\n",
    "        yticks = ax_tril.get_yticks()\n",
    "        ax_tril.spines['bottom'].set_bounds(xticks[1],xticks[-2])\n",
    "        ax_tril.spines['left'].set_bounds(yticks[1],yticks[-2])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        yield fig\n",
    "        \n",
    "        \n",
    "def plot_generalization_curves(ACC, noise_vars):\n",
    "    \n",
    "    #ACC = logit(ACC)\n",
    "    \n",
    "    norm = matplotlib.colors.Normalize(vmin=-noise_vars[0], vmax=noise_vars[-1])\n",
    "    #cmap = matplotlib.cm.get_cmap('RdGy_r')\n",
    "    cmap = sns.cubehelix_palette(9, as_cmap=True)\n",
    "    rgba = lambda x: cmap(norm(x))\n",
    "    \n",
    "    sns.set_context(\"paper\", font_scale=2.5)\n",
    "\n",
    "    fig, axes = plt.subplots(1,3,figsize=(23,3.5), sharey=True)\n",
    "\n",
    "    axes[0].plot(noise_vars, np.diag(ACC))\n",
    "    axes[0].set_xlabel(r\"Test Noise\")\n",
    "    axes[0].set_ylabel(\"Accuracy [%]\")\n",
    "    axes[0].set_title(\"Baseline [Adapt $=$ Test]\")\n",
    "\n",
    "    for i in reversed(range(len(ACC))):\n",
    "        axes[1].plot(noise_vars, ACC[:,i], color = rgba(.3-noise_vars[i]), linewidth=2)\n",
    "        axes[1].plot([noise_vars[i]]*2,[0,1], color = rgba(noise_vars[i]), linestyle=\"--\")\n",
    "        \n",
    "    #axes[1].plot(noise_vars, np.diag(ACC))\n",
    "    \n",
    "    axes[1].set_xlabel(r\"Adapt Noise Level\")\n",
    "    axes[1].set_title(r\"Adapt $\\neq$ Test\")\n",
    "\n",
    "    for i in range(len(ACC)):\n",
    "        axes[2].plot(noise_vars, ACC[i,:], color = rgba(noise_vars[i]), linewidth=2)\n",
    "        axes[2].plot([noise_vars[i]]*2,[0,1], color = rgba(noise_vars[i]), linestyle=\"--\")\n",
    "    axes[2].set_xlabel(r\"Test Noise Level\")\n",
    "    axes[2].set_title(r\"Adapt $\\neq$ Test\")\n",
    "\n",
    "    for ax in axes:\n",
    "        sns.despine(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (only for reference)\n",
    "\n",
    "#! cp ./log/multitask/white/clean/20180820-200745_MultidomainBCESolver/20180820-200745-checkpoint-ep90.pth results/multitask/20180820-200745-checkpoint-ep90-white-clean.pth\n",
    "#! cp ./log/multitask/white/noise/20180820-200902_MultidomainBCESolver/20180820-200902-checkpoint-ep90.pth results/multitask/20180820-200902-checkpoint-ep90-white-noise.pth\n",
    "\n",
    "#! cp ./log/multitask/snp/noise/20180905-170020_MultidomainBCESolver/20180905-170020-checkpoint-ep90.pth results/multitask/20180905-170020-checkpoint-ep90-snp-noise.pth\n",
    "#! cp ./log/multitask/snp/clean/20180905-165820_MultidomainBCESolver/20180905-165820-checkpoint-ep90.pth results/multitask/20180905-165820-checkpoint-ep90-snp-clean.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2176 x 4 adaptable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Noise Adaptation Results here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.instancenorm.InstanceNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "0 4\n",
      "0 4\n"
     ]
    }
   ],
   "source": [
    "titles = {\n",
    "    'noise' : 'Adaptation from High to Low',\n",
    "    'clean' : 'Adaptation from Low to High'\n",
    "}\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import datasets_white, datasets_snp\n",
    "\n",
    "noisemodels = {\n",
    "    \"white\" : {\"clean\" : datasets_white.clean2noise(),\n",
    "               \"noise\" : datasets_white.clean2noise()\n",
    "              },\n",
    "    \"snp\" : {\"clean\" : datasets_snp.clean2noise(),\n",
    "             \"noise\" : datasets_snp.clean2noise()\n",
    "            }\n",
    "}\n",
    "\n",
    "tmpl_fname = 'results/noise/*-checkpoint-ep90-{noise}-{source}.{fmt}'\n",
    "\n",
    "with PdfPages(\"results/noise-plots.pdf\") as pdf:\n",
    "    for noise, sources in noisemodels.items():\n",
    "        for source, noisemodel in sources.items():\n",
    "\n",
    "            assert noise in [\"white\", \"snp\"]\n",
    "            assert source in [\"clean\", \"noise\"]\n",
    "\n",
    "            model_fname, = list(glob.glob(tmpl_fname.format(source=source, noise=noise, fmt=\"pth\")))\n",
    "            eval_fname,  = list(glob.glob(tmpl_fname.format(source=source, noise=noise, fmt=\"hdf5\")))\n",
    "\n",
    "            #print(model_fname, os.path.exists(model_fname))\n",
    "            #print(eval_fname, os.path.exists(eval_fname))\n",
    "\n",
    "            n_domains  = len(noisemodel)\n",
    "\n",
    "            revert = (source == 'noise')\n",
    "            ACC        = analysis.load_file(eval_fname, n_domains=n_domains, revert=revert)\n",
    "            imgs       = np.stack(N(.5 + torch.zeros(28,28)).numpy() for N in noisemodel)\n",
    "            noise_vars = [g.__dict__.get('sigma', 0) + g.__dict__.get('prob', 0) for g in noisemodel]\n",
    "\n",
    "            P      = analysis.load_params([model_fname])\n",
    "            if revert:\n",
    "                P = [p[::-1].copy() for p in P]\n",
    "            M, B   = analysis.compute_linear(P)\n",
    "            P      = list(P) + [M, B]\n",
    "\n",
    "            for fig in plot_full_analysis(ACC, imgs, noise_vars, P, titles[source], sym = \"\\sigma^2\" if noise == \"white\" else \"p\"):\n",
    "                pdf.savefig(fig, bbox_inches='tight')\n",
    "                action()\n",
    "\n",
    "            plot_generalization_curves(ACC, noise_vars)\n",
    "            pdf.savefig(bbox_inches='tight')\n",
    "            action()\n",
    "            #plt.close()\n",
    "\n",
    "            #break\n",
    "        #break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
