{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from salad.datasets import DigitsLoader\n",
    "import torch\n",
    "from salad.datasets.da import NoiseLoader\n",
    "from salad.datasets.transforms import SaltAndPepper\n",
    "from salad.utils import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions for digit dataset multi-class training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def get_data(source):\n",
    "    loader = NoiseLoader('/tmp/data', source, collate = 'stack', noisemodels=[SaltAndPepper(0.15)],batch_size = 32, shuffle = False, split=\"test\", normalize=False)\n",
    "    return loader\n",
    "\n",
    "def run_eval(source, solver, loader):\n",
    "\n",
    "    fname = list(glob.glob(\"log/noise-{}-snp/*{}*/*-checkpoint-ep9.pth\".format(source, solver)))\n",
    "    if len(fname) == 0:\n",
    "        return {}\n",
    "    \n",
    "    fname = fname[0]\n",
    "    \n",
    "    print(fname)\n",
    "\n",
    "    acc = {}\n",
    "\n",
    "    lbl, pred, _ = evaluate.evaluate([fname], loader.datasets[0], domain = 0)\n",
    "    acc[(source, solver)] = [lbl, pred]\n",
    "            \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/synth_test_32x32.mat?raw=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/299 [00:00<00:04, 64.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/noise-synth-snp/20181026-041401_DeepCoralSolver/20181026-041401-checkpoint-ep9.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:05<00:00, 58.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "predictions = {}\n",
    "sources = ['synth']#, 'svhn']\n",
    "solvers = [\n",
    "    #\"AssociativeSolver\",\n",
    "    #\"DANNSolver\",\n",
    "    \"DeepCoralSolver\",\n",
    "    #\"SelfEnsemblingSolver\",\n",
    "    #\"VADASolver\"\n",
    "]\n",
    "\n",
    "for source in sources:\n",
    "    loader = get_data(source)\n",
    "    for solver in solvers:\n",
    "        predictions.update(run_eval(source, solver, loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(\"results/noiseadapt_predictions.hdf5\") as ds:\n",
    "    \n",
    "    for key in predictions:\n",
    "        \n",
    "        ds_key = \"-\".join(key)\n",
    "        \n",
    "        grp = ds.require_group(ds_key)\n",
    "        \n",
    "        lbls, pred = predictions[key]\n",
    "        \n",
    "        grp[\"prediction\"] = pred\n",
    "        grp[\"labels\"] = lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0M\tresults/noiseadapt_predictions.hdf5\n"
     ]
    }
   ],
   "source": [
    "! du -h results/noiseadapt_predictions.hdf5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
